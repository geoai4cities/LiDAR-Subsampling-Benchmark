#!/usr/bin/env python3
"""
Generate side-by-side point cloud visualization comparing subsampling methods.

This script creates visualizations showing:
- Building edge preservation comparison
- Vegetation detail retention
- Method-specific artifacts across different loss levels (30%, 50%, 70%, 90%)

Uses pre-generated subsampled data from data/SemanticKITTI/subsampled/
Reads recommended scans from good_scans.txt (generated by find_good_scans.py)

Visualization style inspired by:
- LitePT: Lighter Yet Stronger Point Transformer (arXiv:2512.13689)
  https://arxiv.org/abs/2512.13689
  Figures 11-13: Oblique 3D views with semantic colors, grid layout comparison

- EZ-SP: Fast and Lightweight Superpoint-Based 3D Segmentation (arXiv:2512.00385)
  https://arxiv.org/abs/2512.00385
  Figure 6: Oblique perspective point cloud visualization

- Superpoint Transformer (ICCV'23)
  https://github.com/drprojects/superpoint_transformer
  Interactive 3D visualization with semantic coloring

For Response to Reviewers - Comment 6.14
"""

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 (required for 3D projection)
from pathlib import Path
import sys

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# SemanticKITTI class colors (RGB, 0-255)
SEMANTICKITTI_COLORS = {
    0: [0, 0, 0],          # unlabeled
    1: [245, 150, 100],    # car
    2: [245, 230, 100],    # bicycle
    3: [150, 60, 30],      # motorcycle
    4: [180, 30, 80],      # truck
    5: [255, 0, 0],        # other-vehicle
    6: [30, 30, 255],      # person
    7: [200, 40, 255],     # bicyclist
    8: [90, 30, 150],      # motorcyclist
    9: [255, 0, 255],      # road
    10: [255, 150, 255],   # parking
    11: [75, 0, 75],       # sidewalk
    12: [75, 0, 175],      # other-ground
    13: [0, 200, 255],     # building
    14: [50, 120, 255],    # fence
    15: [0, 175, 0],       # vegetation
    16: [0, 60, 135],      # trunk
    17: [80, 240, 150],    # terrain
    18: [150, 240, 255],   # pole
    19: [0, 0, 255],       # traffic-sign
}

# Label mapping for SemanticKITTI (from original labels to training labels)
LABEL_MAP = {
    0: 0, 1: 0, 10: 1, 11: 2, 13: 5, 15: 3, 16: 5, 18: 4, 20: 5,
    30: 6, 31: 7, 32: 8, 40: 9, 44: 10, 48: 11, 49: 12, 50: 13,
    51: 14, 52: 0, 60: 9, 70: 15, 71: 16, 72: 17, 80: 18, 81: 19,
    99: 0, 252: 1, 253: 7, 254: 6, 255: 8, 256: 5, 257: 5, 258: 4, 259: 5,
}

# Loss levels and methods for comparison (excluding 10% as not needed)
LOSS_LEVELS = ['30', '50', '70', '90']
METHODS = ['RS', 'FPS', 'Poisson', 'IDIS', 'DBSCAN', 'Voxel']


def get_method_dir(method, loss):
    """Returns the correct directory name for method and loss level.

    RS/FPS/Poisson use seed1 for most losses, seed2 for loss90.
    IDIS/DBSCAN/Voxel have no seed suffix.
    """
    if method in ['IDIS', 'DBSCAN', 'Voxel']:
        return f'{method}_loss{loss}'
    else:  # RS, FPS, Poisson
        seed = '2' if loss == '90' else '1'
        return f'{method}_loss{loss}_seed{seed}'


def load_pointcloud(bin_path):
    """Load point cloud from binary file."""
    points = np.fromfile(bin_path, dtype=np.float32).reshape(-1, 4)
    return points[:, :3]  # x, y, z


def load_labels(label_path):
    """Load semantic labels from label file."""
    labels = np.fromfile(label_path, dtype=np.uint32)
    sem_labels = labels & 0xFFFF  # Lower 16 bits are semantic labels
    # Map to training labels
    mapped_labels = np.vectorize(lambda x: LABEL_MAP.get(x, 0))(sem_labels)
    return mapped_labels


def get_label_colors(labels):
    """Convert labels to RGB colors (vectorized for speed)."""
    # Build color lookup table (max label id + 1)
    max_label = max(SEMANTICKITTI_COLORS.keys())
    color_lut = np.ones((max_label + 1, 3), dtype=np.float32) * 0.5  # default gray
    for label_id, rgb in SEMANTICKITTI_COLORS.items():
        color_lut[label_id] = np.array(rgb) / 255.0

    # Clip labels to valid range and lookup
    safe_labels = np.clip(labels, 0, max_label).astype(np.int32)
    return color_lut[safe_labels]


def extract_region(points, labels, x_range, y_range, z_range=None):
    """Extract points within a specified region."""
    mask = (points[:, 0] >= x_range[0]) & (points[:, 0] <= x_range[1]) & \
           (points[:, 1] >= y_range[0]) & (points[:, 1] <= y_range[1])
    if z_range is not None:
        mask &= (points[:, 2] >= z_range[0]) & (points[:, 2] <= z_range[1])
    return points[mask], labels[mask]


def find_building_region(points, labels, min_points=500):
    """Find a region with building points."""
    building_mask = labels == 13  # building class
    building_points = points[building_mask]

    if len(building_points) < min_points:
        return None

    # Find centroid of building points
    centroid = np.mean(building_points, axis=0)

    # Define region around centroid
    region_size = 15  # meters
    x_range = (centroid[0] - region_size/2, centroid[0] + region_size/2)
    y_range = (centroid[1] - region_size/2, centroid[1] + region_size/2)

    return x_range, y_range


def find_vegetation_region(points, labels, min_points=500):
    """Find a region with vegetation points."""
    veg_mask = labels == 15  # vegetation class
    veg_points = points[veg_mask]

    if len(veg_points) < min_points:
        return None

    # Find centroid of vegetation points
    centroid = np.mean(veg_points, axis=0)

    # Define region around centroid
    region_size = 12  # meters
    x_range = (centroid[0] - region_size/2, centroid[0] + region_size/2)
    y_range = (centroid[1] - region_size/2, centroid[1] + region_size/2)

    return x_range, y_range


def plot_pointcloud_oblique(ax, points, labels, title, point_size=0.5, elev=25, azim=45):
    """Plot point cloud from oblique 3D view with semantic colors.

    Inspired by visualization style from:
    - LitePT (arXiv:2512.13689) Figures 11-13
    - EZ-SP (arXiv:2512.00385) Figure 6
    - Superpoint Transformer (https://github.com/drprojects/superpoint_transformer)

    Args:
        ax: Matplotlib 3D axis
        points: Point cloud array (N, 3)
        labels: Semantic labels (N,)
        title: Subplot title
        point_size: Size of points in scatter plot
        elev: Elevation angle for 3D view (degrees)
        azim: Azimuth angle for 3D view (degrees)
    """
    colors = get_label_colors(labels)

    # Center the point cloud for better visualization
    centroid = np.mean(points, axis=0)
    centered_points = points - centroid

    ax.scatter(centered_points[:, 0], centered_points[:, 1], centered_points[:, 2],
               c=colors, s=point_size, marker='.', alpha=0.9)

    # Set viewing angle (oblique perspective)
    ax.view_init(elev=elev, azim=azim)

    # Clean up axes for publication-quality figure
    ax.set_xlabel('')
    ax.set_ylabel('')
    ax.set_zlabel('')
    ax.set_xticklabels([])
    ax.set_yticklabels([])
    ax.set_zticklabels([])

    # Make panes transparent
    ax.xaxis.pane.fill = False
    ax.yaxis.pane.fill = False
    ax.zaxis.pane.fill = False
    ax.xaxis.pane.set_edgecolor('none')
    ax.yaxis.pane.set_edgecolor('none')
    ax.zaxis.pane.set_edgecolor('none')

    # Hide grid lines
    ax.grid(False)

    # Set equal aspect ratio
    max_range = np.max(np.abs(centered_points)) * 1.1
    ax.set_xlim([-max_range, max_range])
    ax.set_ylim([-max_range, max_range])
    ax.set_zlim([-max_range, max_range])

    ax.set_title(title, fontsize=10, fontweight='bold', pad=2)


def create_all_losses_comparison_figure(original_points, original_labels,
                                         all_subsampled_data, region_name, output_dir):
    """Create comparison figure with all loss levels using oblique 3D views.

    Layout inspired by LitePT (arXiv:2512.13689) Figures 11-13:
    - Grid layout with methods as columns, loss levels as rows
    - Oblique 3D perspective view for each point cloud
    - Semantic coloring consistent across all subplots

    Layout: 5 rows x 7 cols
    - Row 0: Original + method names as headers
    - Rows 1-4: Loss levels 30%, 50%, 70%, 90%
    - Columns: Original, RS, FPS, Poisson, IDIS, DBSCAN, Voxel

    Args:
        original_points: Original point cloud (N, 3)
        original_labels: Original labels (N,)
        all_subsampled_data: Nested dict {method: {loss: (points, labels)}}
        region_name: Name for figure title
        output_dir: Output directory path
    """
    # Set up matplotlib for academic style
    plt.rcParams.update({
        'font.family': 'serif',
        'font.serif': ['Times New Roman', 'DejaVu Serif'],
        'font.size': 10,
        'axes.titlesize': 11,
        'axes.labelsize': 10,
    })

    n_rows = len(LOSS_LEVELS) + 1  # +1 for header row with original
    n_cols = len(METHODS) + 1      # +1 for original/loss label column

    # Create figure with 3D subplots
    fig = plt.figure(figsize=(22, 16))

    # Create subplot grid manually for 3D axes
    # Row 0: Original point cloud + method headers
    # Original in (0, 0) as 3D
    ax_orig = fig.add_subplot(n_rows, n_cols, 1, projection='3d')
    plot_pointcloud_oblique(ax_orig, original_points, original_labels,
                           f'Original\n({len(original_points):,} pts)', point_size=0.6)

    # Method headers in row 0 (as 2D text axes)
    for j, method in enumerate(METHODS):
        ax = fig.add_subplot(n_rows, n_cols, j + 2)
        ax.text(0.5, 0.5, method, fontsize=14, fontweight='bold',
                ha='center', va='center', transform=ax.transAxes)
        ax.axis('off')

    # Rows 1-4: Loss levels with 3D point cloud plots
    for i, loss in enumerate(LOSS_LEVELS):
        row_idx = i + 1

        # First column: loss level label (2D text)
        ax_label = fig.add_subplot(n_rows, n_cols, row_idx * n_cols + 1)
        ax_label.text(0.5, 0.5, f'{loss}% Loss\n({100-int(loss)}% retained)',
                      fontsize=12, fontweight='bold',
                      ha='center', va='center', transform=ax_label.transAxes)
        ax_label.axis('off')

        # Method columns (3D plots)
        for j, method in enumerate(METHODS):
            subplot_idx = row_idx * n_cols + j + 2
            ax = fig.add_subplot(n_rows, n_cols, subplot_idx, projection='3d')

            if method in all_subsampled_data and loss in all_subsampled_data[method]:
                points, labels = all_subsampled_data[method][loss]
                retention = len(points) / len(original_points) * 100
                plot_pointcloud_oblique(ax, points, labels,
                                       f'{len(points):,} pts ({retention:.1f}%)',
                                       point_size=0.8)
            else:
                ax.text2D(0.5, 0.5, 'N/A', fontsize=11, ha='center', va='center',
                         transform=ax.transAxes)
                ax.set_axis_off()

    # Add legend as a separate element
    main_classes = {
        13: 'Building',
        15: 'Vegetation',
        9: 'Road',
        17: 'Terrain',
        1: 'Car',
        18: 'Pole',
    }

    legend_handles = []
    for label_id, name in main_classes.items():
        color = np.array(SEMANTICKITTI_COLORS[label_id]) / 255.0
        handle = plt.scatter([], [], c=[color], s=60, label=name)
        legend_handles.append(handle)

    fig.legend(handles=legend_handles, loc='upper right', fontsize=10,
               frameon=True, title='Semantic Classes', title_fontsize=11,
               bbox_to_anchor=(0.99, 0.98))

    fig.suptitle(f'{region_name} Region - Oblique 3D View\n'
                 f'Subsampling Method Comparison Across Loss Levels',
                 fontsize=14, fontweight='bold', y=0.99)

    # Use subplots_adjust instead of tight_layout for 3D plots
    plt.subplots_adjust(left=0.02, right=0.95, top=0.93, bottom=0.02, wspace=0.05, hspace=0.15)

    # Save figure
    output_path = output_dir / f'10_pointcloud_comparison_all_losses_{region_name.lower()}_oblique.png'
    fig.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"Saved: {output_path}")

    # Also save as PDF
    pdf_path = output_dir / f'10_pointcloud_comparison_all_losses_{region_name.lower()}_oblique.pdf'
    fig.savefig(pdf_path, format='pdf', bbox_inches='tight', facecolor='white')
    print(f"Saved: {pdf_path}")

    plt.close(fig)


def load_good_scans():
    """Load recommended scans from good_scans.txt file."""
    good_scans_file = Path(__file__).parent / 'good_scans.txt'

    scans = {
        'building': ('08', None),
        'vegetation': ('08', None),
        'balanced': ('08', None),
    }

    if not good_scans_file.exists():
        print(f"Warning: {good_scans_file} not found. Run find_good_scans.py first.")
        return scans

    with open(good_scans_file, 'r') as f:
        for line in f:
            line = line.strip()
            if line.startswith('building_scan='):
                parts = line.split('=')[1].split(',')
                scans['building'] = (parts[0], parts[1])
            elif line.startswith('vegetation_scan='):
                parts = line.split('=')[1].split(',')
                scans['vegetation'] = (parts[0], parts[1])
            elif line.startswith('balanced_scan='):
                parts = line.split('=')[1].split(',')
                scans['balanced'] = (parts[0], parts[1])

    return scans


def process_scan(sequence, scan_id, region_type, original_dir, subsampled_base, output_dir):
    """Process a single scan for visualization."""

    velodyne_dir = original_dir / sequence / 'velodyne'
    labels_dir = original_dir / sequence / 'labels'

    bin_path = velodyne_dir / f'{scan_id}.bin'
    label_path = labels_dir / f'{scan_id}.label'

    if not bin_path.exists():
        print(f"Error: Scan not found: {bin_path}")
        return False

    # Load original point cloud and labels
    original_points = load_pointcloud(bin_path)
    original_labels = load_labels(label_path)
    print(f"\nLoaded original: {len(original_points):,} points")

    # Load pre-generated subsampled data for all methods and all loss levels
    print("Loading pre-generated subsampled data for all loss levels...")
    all_subsampled_data = {}  # {method: {loss: (points, labels)}}

    for method in METHODS:
        all_subsampled_data[method] = {}
        for loss in LOSS_LEVELS:
            dir_name = get_method_dir(method, loss)
            method_dir = subsampled_base / dir_name / 'sequences' / sequence / 'velodyne'
            method_label_dir = subsampled_base / dir_name / 'sequences' / sequence / 'labels'

            bin_file = method_dir / f'{scan_id}.bin'
            label_file = method_label_dir / f'{scan_id}.label'

            if bin_file.exists() and label_file.exists():
                points = load_pointcloud(bin_file)
                labels = load_labels(label_file)
                all_subsampled_data[method][loss] = (points, labels)
                print(f"  {method} loss{loss}: {len(points):,} points ({len(points)/len(original_points)*100:.1f}%)")
            else:
                print(f"  {method} loss{loss}: NOT FOUND - {bin_file}")

    # Check if we have any data
    total_loaded = sum(len(v) for v in all_subsampled_data.values())
    if total_loaded == 0:
        print("Error: No subsampled data found!")
        return False

    # Find regions based on type
    if region_type == 'building':
        region = find_building_region(original_points, original_labels)
        region_name = 'Building'
    elif region_type == 'vegetation':
        region = find_vegetation_region(original_points, original_labels)
        region_name = 'Vegetation'
    else:
        # For balanced, use building region as primary
        region = find_building_region(original_points, original_labels)
        region_name = 'Mixed'

    if region is None:
        print(f"Warning: Could not find {region_type} region in scan {scan_id}")
        return False

    x_range, y_range = region
    print(f"Region: x=[{x_range[0]:.1f}, {x_range[1]:.1f}], y=[{y_range[0]:.1f}, {y_range[1]:.1f}]")

    # Extract original region
    orig_region_pts, orig_region_labels = extract_region(
        original_points, original_labels, x_range, y_range)
    print(f"Original region: {len(orig_region_pts):,} points")

    # Extract subsampled regions for all methods and loss levels
    all_subsampled_regions = {}  # {method: {loss: (points, labels)}}
    for method in METHODS:
        all_subsampled_regions[method] = {}
        for loss in LOSS_LEVELS:
            if loss in all_subsampled_data[method]:
                sub_pts, sub_labels = all_subsampled_data[method][loss]
                region_pts, region_labels = extract_region(sub_pts, sub_labels, x_range, y_range)
                if len(region_pts) > 0:
                    all_subsampled_regions[method][loss] = (region_pts, region_labels)
                    print(f"  {method} loss{loss} region: {len(region_pts):,} points")

    # Generate all-losses comparison figure with oblique 3D view
    create_all_losses_comparison_figure(orig_region_pts, orig_region_labels,
                                         all_subsampled_regions, region_name, output_dir)

    return True


def main():
    """Main function to generate point cloud comparison figures."""

    # Paths
    original_dir = PROJECT_ROOT / 'data' / 'SemanticKITTI' / 'original' / 'sequences'
    subsampled_base = PROJECT_ROOT / 'data' / 'SemanticKITTI' / 'subsampled'
    output_dir = PROJECT_ROOT / 'docs' / 'figures'
    output_dir.mkdir(parents=True, exist_ok=True)

    print("="*70)
    print("Point Cloud Comparison Figure Generator")
    print("="*70)

    # Load recommended scans from good_scans.txt
    good_scans = load_good_scans()

    print(f"\nRecommended scans from good_scans.txt:")
    for scan_type, (seq, scan_id) in good_scans.items():
        print(f"  {scan_type}: sequence {seq}, scan {scan_id}")

    # Process building scan
    if good_scans['building'][1] is not None:
        seq, scan_id = good_scans['building']
        print(f"\n{'='*70}")
        print(f"Processing BUILDING scan: sequence {seq}, scan {scan_id}")
        print("="*70)
        process_scan(seq, scan_id, 'building', original_dir, subsampled_base, output_dir)

    # Process vegetation scan
    if good_scans['vegetation'][1] is not None:
        seq, scan_id = good_scans['vegetation']
        print(f"\n{'='*70}")
        print(f"Processing VEGETATION scan: sequence {seq}, scan {scan_id}")
        print("="*70)
        process_scan(seq, scan_id, 'vegetation', original_dir, subsampled_base, output_dir)

    print("\n" + "="*70)
    print("Done! Figures saved to:", output_dir)
    print("\nGenerated figures:")
    print("  - 10_pointcloud_comparison_all_losses_building_oblique.png/pdf")
    print("  - 10_pointcloud_comparison_all_losses_vegetation_oblique.png/pdf")
    print("="*70)


if __name__ == '__main__':
    main()
