#!/usr/bin/env python3
"""
Generate side-by-side point cloud visualization comparing subsampling methods.
Uses Open3D for high-quality point cloud rendering.

================================================================================
HOW TO RUN THIS SCRIPT
================================================================================

1. Activate the virtual environment:

   cd PTv3 && source activate.sh

2. Run with xvfb-run (required for headless servers without display):

   cd scripts/figures
   xvfb-run -a python generate_pointcloud_comparison_o3d.py

   Note: xvfb-run provides a virtual framebuffer for Open3D rendering.
   Without it, you'll get "GLFW Error: Failed to detect any supported platform"

3. Output files will be saved to:
   - docs/figures/
     - 10_pointcloud_comparison_building_o3d.png/pdf
     - 10_pointcloud_comparison_vegetation_o3d.png/pdf

   - docs/figures/figure_10_subplots/
     - building/*.png (individual subplot renders)
     - vegetation/*.png (individual subplot renders)
     - original.ply (PLY file for external viewing)

================================================================================
PREREQUISITES
================================================================================

- Python packages: open3d, numpy, matplotlib, pillow
- Install Open3D if missing: pip install open3d
- xvfb-run must be available (usually pre-installed on Linux servers)

- Subsampled data must exist at:
  data/SemanticKITTI/subsampled/{METHOD}_loss{LEVEL}/sequences/{SEQ}/velodyne/

- good_scans.txt must exist (generated by find_good_scans.py)

================================================================================
DESCRIPTION
================================================================================

This script creates visualizations showing:
- Building edge preservation comparison
- Vegetation detail retention
- Method-specific artifacts across different loss levels (30%, 50%, 70%, 90%)

Uses pre-generated subsampled data from data/SemanticKITTI/subsampled/
Reads recommended scans from good_scans.txt (generated by find_good_scans.py)

Visualization approach inspired by:
- PointCept/LitePT visualization utilities (pointcept/utils/visualization.py)
  Uses Open3D for publication-quality point cloud rendering
- Adds offscreen rendering for automated figure generation

For Response to Reviewers - Comment 6.14
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec
from pathlib import Path
from PIL import Image
import sys
import os
import open3d as o3d

# Set up academic-style plotting (matching other figures in the paper)
plt.rcParams.update({
    # Font settings - use serif fonts for academic papers (IEEE/ACM style)
    'font.family': 'serif',
    'font.serif': ['Times New Roman', 'Times', 'DejaVu Serif', 'serif'],
    'font.size': 14,
    'mathtext.fontset': 'stix',

    # Axes settings
    'axes.labelsize': 16,
    'axes.titlesize': 18,
    'axes.linewidth': 1.2,

    # Tick settings
    'xtick.labelsize': 14,
    'ytick.labelsize': 14,

    # Legend settings
    'legend.fontsize': 13,
    'legend.framealpha': 0.95,

    # Figure settings
    'figure.dpi': 150,
    'savefig.dpi': 300,
    'savefig.bbox': 'tight',
})

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# Import PointCept visualization utilities
try:
    from PTv3.pointcept.pointcept.utils.visualization import (
        to_numpy, save_point_cloud
    )
    POINTCEPT_AVAILABLE = True
    print("Using PointCept visualization utilities")
except ImportError:
    POINTCEPT_AVAILABLE = False
    print("PointCept not available, using built-in functions")

    def to_numpy(x):
        """Convert tensor to numpy array."""
        import torch
        if isinstance(x, torch.Tensor):
            x = x.clone().detach().cpu().numpy()
        assert isinstance(x, np.ndarray)
        return x

# SemanticKITTI class colors (RGB, 0-255)
SEMANTICKITTI_COLORS = {
    0: [0, 0, 0],          # unlabeled
    1: [245, 150, 100],    # car
    2: [245, 230, 100],    # bicycle
    3: [150, 60, 30],      # motorcycle
    4: [180, 30, 80],      # truck
    5: [255, 0, 0],        # other-vehicle
    6: [30, 30, 255],      # person
    7: [200, 40, 255],     # bicyclist
    8: [90, 30, 150],      # motorcyclist
    9: [255, 0, 255],      # road
    10: [255, 150, 255],   # parking
    11: [75, 0, 75],       # sidewalk
    12: [75, 0, 175],      # other-ground
    13: [0, 200, 255],     # building
    14: [50, 120, 255],    # fence
    15: [0, 175, 0],       # vegetation
    16: [0, 60, 135],      # trunk
    17: [80, 240, 150],    # terrain
    18: [150, 240, 255],   # pole
    19: [0, 0, 255],       # traffic-sign
}

# Label mapping for SemanticKITTI (from original labels to training labels)
LABEL_MAP = {
    0: 0, 1: 0, 10: 1, 11: 2, 13: 5, 15: 3, 16: 5, 18: 4, 20: 5,
    30: 6, 31: 7, 32: 8, 40: 9, 44: 10, 48: 11, 49: 12, 50: 13,
    51: 14, 52: 0, 60: 9, 70: 15, 71: 16, 72: 17, 80: 18, 81: 19,
    99: 0, 252: 1, 253: 7, 254: 6, 255: 8, 256: 5, 257: 5, 258: 4, 259: 5,
}

# Loss levels and methods for comparison
LOSS_LEVELS = ['30', '50', '70', '90']
METHODS = ['RS', 'FPS', 'Poisson', 'IDIS', 'DBSCAN', 'Voxel', 'DEPOCO']

# Display names for methods (for figure labels)
METHOD_DISPLAY_NAMES = {
    'RS': 'RS',
    'FPS': 'FPS',
    'Poisson': 'SB',  # Spatial Boundary / Poisson disk sampling
    'IDIS': 'IDIS',
    'DBSCAN': 'DBSCAN',
    'Voxel': 'Voxel',
    'DEPOCO': 'DEPOCO',
}


def get_method_dir(method, loss):
    """Returns the correct directory name for method and loss level."""
    if method in ['IDIS', 'DBSCAN', 'Voxel', 'DEPOCO']:
        return f'{method}_loss{loss}'
    else:  # RS, FPS, Poisson
        seed = '2' if loss == '90' else '1'
        return f'{method}_loss{loss}_seed{seed}'


def load_pointcloud(bin_path):
    """Load point cloud from binary file."""
    points = np.fromfile(bin_path, dtype=np.float32).reshape(-1, 4)
    return points[:, :3]  # x, y, z


def load_labels(label_path):
    """Load semantic labels from label file."""
    labels = np.fromfile(label_path, dtype=np.uint32)
    sem_labels = labels & 0xFFFF  # Lower 16 bits are semantic labels
    mapped_labels = np.vectorize(lambda x: LABEL_MAP.get(x, 0))(sem_labels)
    return mapped_labels


def get_label_colors(labels):
    """Convert labels to RGB colors normalized to [0, 1]."""
    max_label = max(SEMANTICKITTI_COLORS.keys())
    color_lut = np.ones((max_label + 1, 3), dtype=np.float64) * 0.5  # default gray
    for label_id, rgb in SEMANTICKITTI_COLORS.items():
        color_lut[label_id] = np.array(rgb) / 255.0

    safe_labels = np.clip(labels, 0, max_label).astype(np.int32)
    return color_lut[safe_labels]


def extract_region(points, labels, x_range, y_range, z_range=None):
    """Extract points within a specified region."""
    mask = (points[:, 0] >= x_range[0]) & (points[:, 0] <= x_range[1]) & \
           (points[:, 1] >= y_range[0]) & (points[:, 1] <= y_range[1])
    if z_range is not None:
        mask &= (points[:, 2] >= z_range[0]) & (points[:, 2] <= z_range[1])
    return points[mask], labels[mask]


def find_building_region(points, labels, min_points=500):
    """Find a region with building points."""
    building_mask = labels == 13  # building class
    building_points = points[building_mask]

    if len(building_points) < min_points:
        return None

    centroid = np.mean(building_points, axis=0)
    region_size = 15  # meters
    x_range = (centroid[0] - region_size/2, centroid[0] + region_size/2)
    y_range = (centroid[1] - region_size/2, centroid[1] + region_size/2)

    return x_range, y_range


def find_vegetation_region(points, labels, min_points=500):
    """Find a region with vegetation points."""
    veg_mask = labels == 15  # vegetation class
    veg_points = points[veg_mask]

    if len(veg_points) < min_points:
        return None

    centroid = np.mean(veg_points, axis=0)
    region_size = 12  # meters
    x_range = (centroid[0] - region_size/2, centroid[0] + region_size/2)
    y_range = (centroid[1] - region_size/2, centroid[1] + region_size/2)

    return x_range, y_range


def compute_bbox_bounds(points, labels, highlight_class, use_largest_cluster=False):
    """
    Compute bounding box bounds for a specific class.

    This should be called ONCE on the original point cloud to get fixed bounds
    that will be reused for all subsampled versions.

    Args:
        points: Point cloud array (N, 3)
        labels: Label array (N,)
        highlight_class: Class ID to create bounding box around
        use_largest_cluster: If True, find the largest cluster (good for scattered vegetation)

    Returns:
        Tuple of (min_bound, max_bound) as numpy arrays, or (None, None) if no points
    """
    # Find points of the highlight class
    mask = labels == highlight_class
    if not np.any(mask):
        return None, None

    class_points = points[mask]

    # Compute axis-aligned bounding box
    if use_largest_cluster and len(class_points) > 100:
        # Use DBSCAN to find the largest cluster
        try:
            from sklearn.cluster import DBSCAN
            # Use DBSCAN with eps based on point density
            eps = 1.0  # 1 meter neighborhood
            min_samples = 10
            clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(class_points)
            cluster_labels = clustering.labels_

            # Find the largest cluster (excluding noise label -1)
            unique_labels = set(cluster_labels)
            unique_labels.discard(-1)  # Remove noise

            if unique_labels:
                largest_cluster = max(unique_labels, key=lambda l: np.sum(cluster_labels == l))
                cluster_mask = cluster_labels == largest_cluster
                class_points = class_points[cluster_mask]
            # If no valid clusters, fall back to all points
        except ImportError:
            # If sklearn not available, use percentile fallback
            pass

    # Compute bounding box from (possibly clustered) points
    min_bound = np.min(class_points, axis=0)
    max_bound = np.max(class_points, axis=0)

    # Add small padding (2% of extent)
    extent = max_bound - min_bound
    padding = extent * 0.02
    min_bound -= padding
    max_bound += padding

    return min_bound, max_bound


def create_bounding_box_lineset_from_bounds(min_bound, max_bound, box_color=[0.3, 0.3, 0.3], centroid_offset=None):
    """
    Create a 3D bounding box LineSet from pre-computed bounds.

    Args:
        min_bound: Minimum corner of bounding box (3,)
        max_bound: Maximum corner of bounding box (3,)
        box_color: RGB color for the box lines [0-1]
        centroid_offset: If provided, offset the box by this amount (for centered point clouds)

    Returns:
        Open3D LineSet geometry
    """
    if min_bound is None or max_bound is None:
        return None

    # Apply centroid offset if provided (when points are centered)
    if centroid_offset is not None:
        min_bound = min_bound - centroid_offset
        max_bound = max_bound - centroid_offset

    # Define 8 corners of the bounding box
    corners = np.array([
        [min_bound[0], min_bound[1], min_bound[2]],  # 0
        [max_bound[0], min_bound[1], min_bound[2]],  # 1
        [max_bound[0], max_bound[1], min_bound[2]],  # 2
        [min_bound[0], max_bound[1], min_bound[2]],  # 3
        [min_bound[0], min_bound[1], max_bound[2]],  # 4
        [max_bound[0], min_bound[1], max_bound[2]],  # 5
        [max_bound[0], max_bound[1], max_bound[2]],  # 6
        [min_bound[0], max_bound[1], max_bound[2]],  # 7
    ])

    # Define 12 edges of the box
    lines = [
        [0, 1], [1, 2], [2, 3], [3, 0],  # Bottom face
        [4, 5], [5, 6], [6, 7], [7, 4],  # Top face
        [0, 4], [1, 5], [2, 6], [3, 7],  # Vertical edges
    ]

    # Create LineSet
    line_set = o3d.geometry.LineSet()
    line_set.points = o3d.utility.Vector3dVector(corners)
    line_set.lines = o3d.utility.Vector2iVector(lines)
    line_set.colors = o3d.utility.Vector3dVector([box_color] * len(lines))

    return line_set


def create_bounding_box_lineset(points, labels, highlight_class, box_color=[0.3, 0.3, 0.3], line_width=2.0, use_largest_cluster=False):
    """
    Create a 3D bounding box LineSet around points of a specific class.

    DEPRECATED: Use compute_bbox_bounds() once on original, then create_bounding_box_lineset_from_bounds()
    for each render. This function is kept for backward compatibility.

    Args:
        points: Point cloud array (N, 3) - already centered
        labels: Label array (N,)
        highlight_class: Class ID to create bounding box around (e.g., 13 for building, 15 for vegetation)
        box_color: RGB color for the box lines [0-1]
        line_width: Width of box lines
        use_largest_cluster: If True, find the largest cluster and draw box around it (good for scattered vegetation)

    Returns:
        Open3D LineSet geometry or None if no points of that class
    """
    min_bound, max_bound = compute_bbox_bounds(points, labels, highlight_class, use_largest_cluster)
    if min_bound is None:
        return None

    # Define 8 corners of the bounding box
    corners = np.array([
        [min_bound[0], min_bound[1], min_bound[2]],  # 0
        [max_bound[0], min_bound[1], min_bound[2]],  # 1
        [max_bound[0], max_bound[1], min_bound[2]],  # 2
        [min_bound[0], max_bound[1], min_bound[2]],  # 3
        [min_bound[0], min_bound[1], max_bound[2]],  # 4
        [max_bound[0], min_bound[1], max_bound[2]],  # 5
        [max_bound[0], max_bound[1], max_bound[2]],  # 6
        [min_bound[0], max_bound[1], max_bound[2]],  # 7
    ])

    # Define 12 edges of the box
    lines = [
        [0, 1], [1, 2], [2, 3], [3, 0],  # Bottom face
        [4, 5], [5, 6], [6, 7], [7, 4],  # Top face
        [0, 4], [1, 5], [2, 6], [3, 7],  # Vertical edges
    ]

    # Create LineSet
    line_set = o3d.geometry.LineSet()
    line_set.points = o3d.utility.Vector3dVector(corners)
    line_set.lines = o3d.utility.Vector2iVector(lines)
    line_set.colors = o3d.utility.Vector3dVector([box_color] * len(lines))

    return line_set


def render_pointcloud_o3d(points, colors, output_path, width=400, height=400,
                          point_size=2.0, bg_color=[1, 1, 1], save_ply=False,
                          point_count=None, add_label=True,
                          bbox_bounds=None, box_color=[0.3, 0.3, 0.3]):
    """
    Render point cloud to image using Open3D offscreen rendering.

    Extends PointCept's visualization utilities with offscreen rendering
    for automated publication figure generation.

    NOTE: Run this script with xvfb-run for headless servers:
        xvfb-run -a python generate_pointcloud_comparison_o3d.py

    Args:
        points: Point cloud array (N, 3)
        colors: RGB colors array (N, 3) in range [0, 1]
        output_path: Path to save the rendered image
        width: Image width
        height: Image height
        point_size: Size of rendered points
        bg_color: Background color [R, G, B] in range [0, 1]
        save_ply: Also save as PLY file (using PointCept's save_point_cloud)
        point_count: Number of points (for annotation)
        add_label: Add point count label to image
        bbox_bounds: Pre-computed bounding box as (min_bound, max_bound) tuple. Computed once from original.
        box_color: RGB color for the bounding box lines [0-1]
    """
    if point_count is None:
        point_count = len(points)

    # Center the point cloud
    centroid = np.mean(points, axis=0)
    centered_points = points - centroid

    # Create Open3D point cloud
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(centered_points.astype(np.float64))
    pcd.colors = o3d.utility.Vector3dVector(colors.astype(np.float64))

    # Optionally save PLY file using PointCept's utility
    if save_ply and POINTCEPT_AVAILABLE:
        ply_path = str(output_path).replace('.png', '.ply')
        save_point_cloud(centered_points, colors, ply_path)

    # Create visualizer for offscreen rendering
    vis = o3d.visualization.Visualizer()
    vis.create_window(visible=False, width=width, height=height)
    vis.add_geometry(pcd)

    # Add bounding box if pre-computed bounds are provided
    if bbox_bounds is not None:
        min_bound, max_bound = bbox_bounds
        bbox_lineset = create_bounding_box_lineset_from_bounds(
            min_bound, max_bound, box_color=box_color, centroid_offset=centroid
        )
        if bbox_lineset is not None:
            vis.add_geometry(bbox_lineset)

    # Get render options and set point size
    render_opt = vis.get_render_option()
    render_opt.point_size = point_size
    render_opt.background_color = np.array(bg_color)
    render_opt.line_width = 8.0  # Thick lines for bounding box visibility

    # Set camera view (oblique perspective)
    ctr = vis.get_view_control()

    # Set camera parameters for oblique view
    elev_rad = np.radians(25)  # elevation angle
    azim_rad = np.radians(45)  # azimuth angle

    front = np.array([
        np.cos(elev_rad) * np.sin(azim_rad),
        np.cos(elev_rad) * np.cos(azim_rad),
        np.sin(elev_rad)
    ])

    ctr.set_front(front)
    ctr.set_up([0, 0, 1])  # Z is up
    ctr.set_lookat([0, 0, 0])  # Look at center
    ctr.set_zoom(0.5)  # Closer zoom for better detail visibility

    # Render and capture
    vis.poll_events()
    vis.update_renderer()

    # Capture to image
    image = vis.capture_screen_float_buffer(do_render=True)
    vis.destroy_window()

    # Convert to numpy
    img_array = (np.asarray(image) * 255).astype(np.uint8)

    # Add point count label if requested
    if add_label and point_count is not None:
        img_array = add_point_count_label(img_array, point_count)

    # Save image
    img = Image.fromarray(img_array)
    img.save(output_path)

    return img_array


def add_point_count_label(img_array, point_count):
    """Add point count label to top-center with academic styling."""
    from PIL import ImageDraw, ImageFont

    img = Image.fromarray(img_array)
    draw = ImageDraw.Draw(img)

    # Format point count (compact format for academic figures)
    if point_count >= 1000:
        label = f"n={point_count:,}"
    else:
        label = f"n={point_count}"

    # Use same serif font as legend (matplotlib default serif)
    font = None
    font_paths = [
        "/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf",  # Bold serif (same as legend title)
        "/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf",       # Serif
        "/usr/share/fonts/truetype/liberation/LiberationSerif-Bold.ttf",
        "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf",   # Sans fallback
    ]

    font_size = 28  # Large for readability in final scaled figure
    for font_path in font_paths:
        try:
            font = ImageFont.truetype(font_path, font_size)
            break
        except:
            continue

    if font is None:
        font = ImageFont.load_default()

    # Get text size
    bbox = draw.textbbox((0, 0), label, font=font)
    text_width = bbox[2] - bbox[0]
    text_height = bbox[3] - bbox[1]

    # Position at top-center
    margin = 8
    x = (img.width - text_width) // 2  # Center horizontally
    y = margin

    # Draw text directly without bounding box (cleaner academic style)
    draw.text((x, y), label, fill=(0, 0, 0), font=font)

    return np.array(img)


def create_text_image(text, width=400, height=400, fontsize=18, bold=True):
    """Create a simple text image using matplotlib with academic-style fonts."""
    import io

    fig, ax = plt.subplots(figsize=(width/100, height/100), dpi=100)
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.axis('off')

    weight = 'bold' if bold else 'normal'
    ax.text(0.5, 0.5, text, fontsize=fontsize, fontweight=weight,
            ha='center', va='center', transform=ax.transAxes,
            fontfamily='serif')

    fig.patch.set_facecolor('white')
    ax.set_facecolor('white')

    # Convert to image array using buffer
    buf = io.BytesIO()
    fig.savefig(buf, format='png', dpi=100, bbox_inches='tight', pad_inches=0,
                facecolor='white')
    buf.seek(0)
    img = Image.open(buf)
    img_array = np.array(img.convert('RGB'))
    plt.close(fig)
    buf.close()

    # Resize to exact dimensions
    img_resized = Image.fromarray(img_array).resize((width, height))
    return np.array(img_resized)


def create_legend_image(width=300, height=400, region_type='building', box_color=[0.0, 0.6, 0.8]):
    """Create a legend image for semantic classes and bounding box with academic-style fonts."""
    import io
    from matplotlib.patches import Rectangle, FancyBboxPatch
    from matplotlib.lines import Line2D

    main_classes = {
        13: 'Building',
        15: 'Vegetation',
        9: 'Road',
        11: 'Sidewalk',
        10: 'Parking',
        17: 'Terrain',
        1: 'Car',
        18: 'Pole',
        14: 'Fence',
        16: 'Trunk',
    }

    fig, ax = plt.subplots(figsize=(width/100, height/100), dpi=100)
    ax.axis('off')

    # Calculate positions with better spacing
    n_classes = len(main_classes)
    # Leave room for title at top and bounding box section at bottom
    y_title = 0.95
    y_start = 0.85  # First class item starts here (below title)
    y_end = 0.25    # Last class item ends here
    y_positions = np.linspace(y_start, y_end, n_classes)

    # Semantic classes section title
    ax.text(0.5, y_title, 'Semantic Classes', fontsize=11, fontweight='bold',
            fontfamily='serif', ha='center', va='top')

    # Draw semantic class legend items with proper spacing
    for i, (label_id, name) in enumerate(main_classes.items()):
        color = np.array(SEMANTICKITTI_COLORS[label_id]) / 255.0
        ax.scatter([0.1], [y_positions[i]], c=[color], s=120, marker='s', edgecolors='none')
        ax.text(0.2, y_positions[i], name, fontsize=9, va='center',
                fontweight='normal', fontfamily='serif')

    # Add separator line
    ax.axhline(y=0.18, xmin=0.05, xmax=0.95, color='gray', linewidth=0.5, linestyle='-')

    # Bounding Box section title
    ax.text(0.5, 0.14, 'Bounding Box', fontsize=11, fontweight='bold',
            fontfamily='serif', ha='center', va='top')

    # Draw a small 3D wireframe box icon using the actual box_color
    box_y = 0.05
    box_x = 0.12
    box_size = 0.045

    # Draw wireframe cube (simplified 2D representation)
    # Front face
    front_rect = Rectangle((box_x - box_size/2, box_y - box_size/2),
                           box_size, box_size,
                           fill=False, edgecolor=box_color, linewidth=3)
    ax.add_patch(front_rect)

    # Back face (offset)
    offset = box_size * 0.4
    back_rect = Rectangle((box_x - box_size/2 + offset, box_y - box_size/2 + offset),
                          box_size, box_size,
                          fill=False, edgecolor=box_color, linewidth=3)
    ax.add_patch(back_rect)

    # Connecting lines (corners)
    for dx, dy in [(- box_size/2, -box_size/2), (box_size/2, -box_size/2),
                   (box_size/2, box_size/2), (-box_size/2, box_size/2)]:
        ax.plot([box_x + dx, box_x + dx + offset],
               [box_y + dy, box_y + dy + offset],
               color=box_color, linewidth=3)

    # Label for bounding box
    highlight_name = 'Building' if region_type == 'building' else 'Vegetation'
    ax.text(0.22, box_y, f'{highlight_name} Region', fontsize=9, va='center',
            fontweight='normal', fontfamily='serif')

    ax.set_xlim(0, 1)
    ax.set_ylim(-0.02, 1.02)

    fig.patch.set_facecolor('white')

    # Convert to image array using buffer
    buf = io.BytesIO()
    fig.savefig(buf, format='png', dpi=100, bbox_inches='tight', pad_inches=0.02,
                facecolor='white')
    buf.seek(0)
    img = Image.open(buf)
    img_array = np.array(img.convert('RGB'))
    plt.close(fig)
    buf.close()

    # Resize to exact dimensions
    img_resized = Image.fromarray(img_array).resize((width, height))
    return np.array(img_resized)


def create_bottom_legend(width, height, region_type='building', original_count=0, box_color=[0.9, 0.1, 0.1]):
    """Create a compact horizontal legend for the bottom of the figure."""
    import io
    from matplotlib.patches import Rectangle

    # Main semantic classes to show (most important ones)
    main_classes = {
        13: 'Building',
        15: 'Vegetation',
        9: 'Road',
        11: 'Sidewalk',
        17: 'Terrain',
        1: 'Car',
        18: 'Pole',
        14: 'Fence',
        16: 'Trunk',
        10: 'Parking',
    }

    fig, ax = plt.subplots(figsize=(width/100, height/100), dpi=100)
    ax.axis('off')

    # Horizontal layout: [● Label] [● Label] ... with text next to circles
    # Include bounding box as part of the uniform spacing (11 items total)
    n_items = len(main_classes)
    x_positions = np.linspace(0.02, 0.68, n_items)  # 10 semantic classes

    # Calculate spacing between items
    spacing = x_positions[1] - x_positions[0] if len(x_positions) > 1 else 0.07

    for i, (label_id, name) in enumerate(main_classes.items()):
        color = np.array(SEMANTICKITTI_COLORS[label_id]) / 255.0
        # Color circle
        ax.scatter([x_positions[i]], [0.5], c=[color], s=200, marker='o', edgecolors='none')
        # Text label next to circle (to the right)
        ax.text(x_positions[i] + 0.012, 0.5, name, fontsize=12, va='center', ha='left',
                fontweight='normal', fontfamily='serif')

    # Bounding box at uniform spacing after last item
    box_x = x_positions[-1] + spacing
    box_y = 0.5
    box_w = 0.012  # Width in x (reduced)
    box_h = 0.20   # Height in y (reduced)
    offset_x = 0.006
    offset_y = 0.10

    # Front face (rectangle)
    front_rect = Rectangle((box_x - box_w/2, box_y - box_h/2),
                           box_w, box_h,
                           fill=False, edgecolor=box_color, linewidth=2.5)
    ax.add_patch(front_rect)

    # Back face (offset rectangle)
    back_rect = Rectangle((box_x - box_w/2 + offset_x, box_y - box_h/2 + offset_y),
                          box_w, box_h,
                          fill=False, edgecolor=box_color, linewidth=2.5)
    ax.add_patch(back_rect)

    # Connecting lines (4 corners)
    corners = [(-box_w/2, -box_h/2), (box_w/2, -box_h/2),
               (box_w/2, box_h/2), (-box_w/2, box_h/2)]
    for dx, dy in corners:
        ax.plot([box_x + dx, box_x + dx + offset_x],
               [box_y + dy, box_y + dy + offset_y],
               color=box_color, linewidth=2.5)

    # Bounding box label and original n value combined
    region_name = 'Building' if region_type == 'building' else 'Vegetation'
    ax.text(box_x + 0.025, 0.5, f'{region_name} Region,  n(Original) = {original_count:,}',
            fontsize=12, va='center', ha='left',
            fontweight='bold', fontfamily='serif')

    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    fig.patch.set_facecolor('white')

    buf = io.BytesIO()
    fig.savefig(buf, format='png', dpi=100, bbox_inches='tight', pad_inches=0.02,
                facecolor='white')
    buf.seek(0)
    img = Image.open(buf)
    img_array = np.array(img.convert('RGB'))
    plt.close(fig)
    buf.close()

    img_resized = Image.fromarray(img_array).resize((width, height))
    return np.array(img_resized)


def assemble_grid_figure(subplot_dir, region_name, output_dir,
                         original_count, all_counts,
                         region_type='building', box_color=[0.0, 0.6, 0.8]):
    """
    Assemble individual subplot images into final grid figure.

    Compact academic layout:
    - Row 0: Method headers (small)
    - Rows 1-4: Loss levels with method subplots
    - Legend at bottom (horizontal, compact)
    - Original n= value shown instead of full image
    """
    import io

    # Cell dimensions
    cell_width, cell_height = 350, 350
    header_height = 50  # Header row
    label_width = 100   # Loss labels column

    n_rows = len(LOSS_LEVELS)
    n_cols = len(METHODS)

    # Calculate grid dimensions
    grid_width = label_width + (cell_width * n_cols)
    grid_height = header_height + (cell_height * n_rows)

    # Bottom legend height
    legend_height = 80

    # Total figure dimensions (no left panel, legend at bottom)
    fig_width = grid_width + 20  # Small margin
    fig_height = grid_height + legend_height + 20

    canvas = np.ones((fig_height, fig_width, 3), dtype=np.uint8) * 255

    # Grid starts at left edge
    grid_x_offset = 10

    # Method headers (Row 0) - use display names with larger fonts
    for j, method in enumerate(METHODS):
        display_name = METHOD_DISPLAY_NAMES.get(method, method)
        header_img = create_text_image(display_name, cell_width, header_height, fontsize=18, bold=True)
        x_start = grid_x_offset + label_width + (j * cell_width)
        canvas[0:header_height, x_start:x_start + cell_width] = header_img[:, :, :3]

    # Grid rows (loss levels)
    for i, loss in enumerate(LOSS_LEVELS):
        y_start = header_height + (i * cell_height)

        # Loss level label (narrow column) - just percentage
        label_text = f'{loss}%'
        label_img = create_text_image(label_text, label_width, cell_height, fontsize=18, bold=True)
        canvas[y_start:y_start + cell_height, grid_x_offset:grid_x_offset + label_width] = label_img[:, :, :3]

        # Method subplots
        for j, method in enumerate(METHODS):
            x_start = grid_x_offset + label_width + (j * cell_width)

            subplot_path = subplot_dir / f'{method}_loss{loss}.png'
            if subplot_path.exists():
                img = np.array(Image.open(subplot_path).resize((cell_width, cell_height)))
                canvas[y_start:y_start + cell_height, x_start:x_start + cell_width] = img[:, :, :3]
            else:
                # N/A placeholder
                na_img = create_text_image('N/A', cell_width, cell_height, fontsize=18, bold=False)
                canvas[y_start:y_start + cell_height, x_start:x_start + cell_width] = na_img[:, :, :3]

    # === Add solid separator lines between methods ===
    line_color = [100, 100, 100]  # Dark gray for better visibility
    line_thickness = 2  # Thicker lines for clarity

    # Vertical separators between method columns (full height including header)
    for j in range(1, n_cols):
        x_line = grid_x_offset + label_width + (j * cell_width)
        canvas[0:grid_height, x_line:x_line + line_thickness] = line_color

    # First vertical line (left edge of grid, before RS)
    x_first = grid_x_offset + label_width
    canvas[0:grid_height, x_first:x_first + line_thickness] = line_color

    # Last vertical line (right edge of grid, after DEPOCO)
    x_last = grid_x_offset + label_width + (n_cols * cell_width)
    canvas[0:grid_height, x_last:x_last + line_thickness] = line_color

    # Horizontal separator below header row (between method names and first data row)
    canvas[header_height:header_height + line_thickness, grid_x_offset + label_width:grid_x_offset + label_width + (n_cols * cell_width) + line_thickness] = line_color

    # Horizontal separators between loss level rows
    for i in range(1, n_rows):
        y_line = header_height + (i * cell_height)
        canvas[y_line:y_line + line_thickness, grid_x_offset + label_width:grid_x_offset + label_width + (n_cols * cell_width) + line_thickness] = line_color

    # Separator line between loss labels and grid (vertical, from header to bottom)
    x_sep = grid_x_offset + label_width
    canvas[header_height:grid_height, x_sep:x_sep + line_thickness] = line_color

    # === Bottom legend (horizontal, compact) ===
    legend_img = create_bottom_legend(grid_width - 20, legend_height,
                                       region_type=region_type,
                                       original_count=original_count,
                                       box_color=box_color)
    legend_y = grid_height + 10
    canvas[legend_y:legend_y + legend_height, grid_x_offset + 10:grid_x_offset + grid_width - 10] = legend_img[:, :, :3]

    # No title - will be written in figure caption instead
    final_img = Image.fromarray(canvas)

    # Save PNG
    output_path = output_dir / f'10_pointcloud_comparison_{region_name.lower()}_o3d.png'
    final_img.save(output_path, dpi=(300, 300))
    print(f"Saved: {output_path}")

    # Save PDF
    pdf_path = output_dir / f'10_pointcloud_comparison_{region_name.lower()}_o3d.pdf'
    final_img.save(pdf_path, format='PDF', resolution=300)
    print(f"Saved: {pdf_path}")

    # Save SVG (convert PIL image to matplotlib figure for SVG export)
    import matplotlib.pyplot as plt
    svg_path = output_dir / f'10_pointcloud_comparison_{region_name.lower()}_o3d.svg'
    fig_svg, ax_svg = plt.subplots(figsize=(fig_width/100, fig_height/100), dpi=100)
    ax_svg.imshow(canvas)
    ax_svg.axis('off')
    fig_svg.savefig(svg_path, format='svg', bbox_inches='tight', pad_inches=0)
    plt.close(fig_svg)
    print(f"Saved: {svg_path}")

    return output_path


def load_good_scans():
    """Load recommended scans from good_scans.txt file."""
    good_scans_file = Path(__file__).parent / 'good_scans.txt'

    scans = {
        'building': ('08', None),
        'vegetation': ('08', None),
        'balanced': ('08', None),
    }

    if not good_scans_file.exists():
        print(f"Warning: {good_scans_file} not found. Run find_good_scans.py first.")
        return scans

    with open(good_scans_file, 'r') as f:
        for line in f:
            line = line.strip()
            if line.startswith('building_scan='):
                parts = line.split('=')[1].split(',')
                scans['building'] = (parts[0], parts[1])
            elif line.startswith('vegetation_scan='):
                parts = line.split('=')[1].split(',')
                scans['vegetation'] = (parts[0], parts[1])
            elif line.startswith('balanced_scan='):
                parts = line.split('=')[1].split(',')
                scans['balanced'] = (parts[0], parts[1])

    return scans


def process_scan(sequence, scan_id, region_type, original_dir, subsampled_base,
                 output_dir, subplot_dir):
    """Process a single scan for visualization."""

    velodyne_dir = original_dir / sequence / 'velodyne'
    labels_dir = original_dir / sequence / 'labels'

    bin_path = velodyne_dir / f'{scan_id}.bin'
    label_path = labels_dir / f'{scan_id}.label'

    if not bin_path.exists():
        print(f"Error: Scan not found: {bin_path}")
        return False

    # Load original point cloud and labels
    original_points = load_pointcloud(bin_path)
    original_labels = load_labels(label_path)
    print(f"\nLoaded original: {len(original_points):,} points")

    # Find region based on type and set highlight class for bounding box
    # Use red for bounding box - high contrast, stands out, doesn't conflict with semantic colors
    box_color = [0.9, 0.1, 0.1]  # Red - universal highlight color

    if region_type == 'building':
        region = find_building_region(original_points, original_labels)
        region_name = 'Building'
        highlight_class = 13  # Building class ID
        use_largest_cluster = False  # Buildings are compact, use full extent
    elif region_type == 'vegetation':
        region = find_vegetation_region(original_points, original_labels)
        region_name = 'Vegetation'
        highlight_class = 15  # Vegetation class ID
        use_largest_cluster = True  # Vegetation is scattered, find largest cluster
    else:
        region = find_building_region(original_points, original_labels)
        region_name = 'Mixed'
        highlight_class = None
        use_largest_cluster = False

    if region is None:
        print(f"Warning: Could not find {region_type} region in scan {scan_id}")
        return False

    x_range, y_range = region
    print(f"Region: x=[{x_range[0]:.1f}, {x_range[1]:.1f}], y=[{y_range[0]:.1f}, {y_range[1]:.1f}]")

    # Create region-specific subplot directory
    region_subplot_dir = subplot_dir / region_name.lower()
    region_subplot_dir.mkdir(parents=True, exist_ok=True)

    # Extract original region
    orig_region_pts, orig_region_labels = extract_region(
        original_points, original_labels, x_range, y_range)
    orig_colors = get_label_colors(orig_region_labels)

    print(f"Original region: {len(orig_region_pts):,} points")

    # Compute bounding box ONCE from original - this will be reused for all subsampled versions
    bbox_bounds = None
    if highlight_class is not None:
        print(f"Computing bounding box from original {region_name.lower()} points...")
        bbox_bounds = compute_bbox_bounds(
            orig_region_pts, orig_region_labels, highlight_class,
            use_largest_cluster=use_largest_cluster
        )
        if bbox_bounds[0] is not None:
            print(f"  Bounding box computed (fixed for all loss levels)")

    print("Rendering original with Open3D...")

    render_pointcloud_o3d(
        orig_region_pts, orig_colors,
        region_subplot_dir / 'original.png',
        width=500, height=500, point_size=4.0,  # Larger size for better visibility
        point_count=len(orig_region_pts), save_ply=True,
        bbox_bounds=bbox_bounds, box_color=box_color
    )

    # Track point counts for annotations
    all_counts = {}

    # Load and render subsampled data
    print("\nRendering subsampled point clouds...")
    for method in METHODS:
        all_counts[method] = {}
        for loss in LOSS_LEVELS:
            dir_name = get_method_dir(method, loss)
            method_dir = subsampled_base / dir_name / 'sequences' / sequence / 'velodyne'
            method_label_dir = subsampled_base / dir_name / 'sequences' / sequence / 'labels'

            bin_file = method_dir / f'{scan_id}.bin'
            label_file = method_label_dir / f'{scan_id}.label'

            if bin_file.exists() and label_file.exists():
                # Load full point cloud
                points = load_pointcloud(bin_file)
                labels = load_labels(label_file)

                # Extract region
                region_pts, region_labels = extract_region(points, labels, x_range, y_range)

                if len(region_pts) > 0:
                    region_colors = get_label_colors(region_labels)
                    all_counts[method][loss] = len(region_pts)

                    output_path = region_subplot_dir / f'{method}_loss{loss}.png'
                    print(f"  {method} loss{loss}: {len(region_pts):,} points")

                    render_pointcloud_o3d(
                        region_pts, region_colors,
                        output_path,
                        width=500, height=500, point_size=4.0,  # Larger points for visibility
                        point_count=len(region_pts), save_ply=False,
                        bbox_bounds=bbox_bounds, box_color=box_color
                    )
                else:
                    print(f"  {method} loss{loss}: No points in region")
            else:
                print(f"  {method} loss{loss}: NOT FOUND")

    # Assemble final grid figure
    print("\nAssembling final grid figure...")
    assemble_grid_figure(
        region_subplot_dir, region_name, output_dir,
        len(orig_region_pts), all_counts,
        region_type=region_type, box_color=box_color
    )

    return True


def main():
    """Main function to generate point cloud comparison figures."""

    # Paths
    original_dir = PROJECT_ROOT / 'data' / 'SemanticKITTI' / 'original' / 'sequences'
    subsampled_base = PROJECT_ROOT / 'data' / 'SemanticKITTI' / 'subsampled'
    output_dir = PROJECT_ROOT / 'docs' / 'figures'
    subplot_dir = output_dir / 'figure_10_subplots'

    output_dir.mkdir(parents=True, exist_ok=True)
    subplot_dir.mkdir(parents=True, exist_ok=True)

    print("="*70)
    print("Point Cloud Comparison Figure Generator (Open3D)")
    print("="*70)

    # Load recommended scans
    good_scans = load_good_scans()

    print(f"\nRecommended scans from good_scans.txt:")
    for scan_type, (seq, scan_id) in good_scans.items():
        print(f"  {scan_type}: sequence {seq}, scan {scan_id}")

    # Process building scan
    if good_scans['building'][1] is not None:
        seq, scan_id = good_scans['building']
        print(f"\n{'='*70}")
        print(f"Processing BUILDING scan: sequence {seq}, scan {scan_id}")
        print("="*70)
        process_scan(seq, scan_id, 'building', original_dir, subsampled_base,
                    output_dir, subplot_dir)

    # Process vegetation scan
    if good_scans['vegetation'][1] is not None:
        seq, scan_id = good_scans['vegetation']
        print(f"\n{'='*70}")
        print(f"Processing VEGETATION scan: sequence {seq}, scan {scan_id}")
        print("="*70)
        process_scan(seq, scan_id, 'vegetation', original_dir, subsampled_base,
                    output_dir, subplot_dir)

    print("\n" + "="*70)
    print("Done! Figures saved to:", output_dir)
    print("\nGenerated figures:")
    print("  - 10_pointcloud_comparison_building_o3d.{png,svg,pdf}")
    print("  - 10_pointcloud_comparison_vegetation_o3d.{png,svg,pdf}")
    print("\nSubplot images saved to:", subplot_dir)
    print("="*70)


if __name__ == '__main__':
    main()
